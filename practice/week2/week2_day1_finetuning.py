"""
Week 2 Day 1-2: 大模型微调 (Fine-tuning)
阿里云大模型ACP认证备考 - 考试占比 16%

运行: python week2_day1_finetuning.py
"""


def exercise1_selection():
    """练习1: 技术选型"""
    print("=" * 60)
    print("练习1: 微调 vs RAG vs Prompt 选择")
    print("=" * 60)

    print("""
📊 技术选型决策

┌─────────────────────────────────────────────────────────────┐
│ 场景                    │ 方案      │ 原因                 │
├─────────────────────────────────────────────────────────────┤
│ 企业文档问答            │ RAG      │ 知识可更新，可溯源   │
│ 特定写作风格            │ 微调     │ 需要改变输出风格     │
│ 代码添加注释要求        │ Prompt   │ 提示词说明即可       │
│ 医疗术语理解            │ 微调     │ 需要学习专业概念     │
│ 实时数据查询            │ RAG      │ 数据频繁更新         │
│ 固定JSON格式输出        │ 微调     │ 需要稳定格式         │
└─────────────────────────────────────────────────────────────┘

💡 核心区分:
  - 缺知识 → RAG
  - 改风格 → 微调
  - 改格式 → Prompt 或 微调
""")


def exercise2_lora():
    """练习2: LoRA 原理"""
    print("\n" + "=" * 60)
    print("练习2: LoRA/QLoRA 原理")
    print("=" * 60)

    print("""
📊 LoRA (Low-Rank Adaptation)

原理: W' = W + BA  (低秩分解)

参数量对比:
  全参数: d × d (巨大)
  LoRA:   2 × d × r (r << d)
  
  例: d=4096, r=8 → 参数减少 256 倍!

┌────────────────┬─────────────────────────────────────────────┐
│ 参数            │ 说明                                       │
├────────────────┼─────────────────────────────────────────────┤
│ r (rank)       │ 秩，常用 8/16/32，越大表达能力越强          │
│ lora_alpha     │ 缩放因子，通常 = 2×r                        │
│ target_modules │ 应用LoRA的层，如 q_proj, v_proj             │
└────────────────┴─────────────────────────────────────────────┘

QLoRA = LoRA + 4-bit量化 → 显存需求再降 ~75%

💡 考点: LoRA = 低秩分解，参数量 ~0.1%
""")


def exercise3_data_format():
    """练习3: 数据格式"""
    print("\n" + "=" * 60)
    print("练习3: 微调数据格式")
    print("=" * 60)

    print("""
📊 数据格式

指令格式 (Alpaca):
{
  "instruction": "翻译成英文",
  "input": "今天天气很好",
  "output": "The weather is nice today"
}

对话格式:
{
  "conversations": [
    {"role": "user", "content": "你好"},
    {"role": "assistant", "content": "你好！"}
  ]
}

📊 数据量建议

┌─────────────────┬──────────────┐
│ 任务类型         │ 建议数据量    │
├─────────────────┼──────────────┤
│ 简单分类         │ 100-500      │
│ 对话风格         │ 500-2000     │
│ 专业领域         │ 2000-10000   │
└─────────────────┴──────────────┘

💡 质量 > 数量: 准确、一致、多样、无重复
""")


def exercise4_training():
    """练习4: 训练参数"""
    print("\n" + "=" * 60)
    print("练习4: 训练参数")
    print("=" * 60)

    print("""
📊 核心参数及问题诊断

┌──────────────────┬───────────────┬─────────────────────────┐
│ 参数              │ 常见值        │ 问题诊断               │
├──────────────────┼───────────────┼─────────────────────────┤
│ learning_rate    │ 1e-5 ~ 5e-5  │ 过大→不稳定 过小→收敛慢 │
│ epochs           │ 3-5          │ 过多→过拟合 过少→欠拟合 │
│ batch_size       │ 4-32         │ 越大越稳定，显存需求高  │
└──────────────────┴───────────────┴─────────────────────────┘

过拟合信号: 训练loss低，验证loss高
欠拟合信号: 两个loss都高

💡 考点速记:
  - lr↑ = 不稳定, epochs↑ = 过拟合
""")


def exercise5_bailian():
    """练习5: 百炼微调流程"""
    print("\n" + "=" * 60)
    print("练习5: 百炼微调流程")
    print("=" * 60)

    print("""
📊 百炼平台微调步骤

1. 准备数据集 → 上传 JSONL 文件
2. 创建微调任务 → 选择基础模型
3. 配置参数 → 设置训练参数
4. 启动训练 → 监控 loss 曲线
5. 模型评测 → 测试效果
6. 部署上线 → 发布 API

📊 部署方案
  - vLLM: 高性能推理引擎
  - PAI-EAS: 企业级部署
  - FC: Serverless 无服务器
""")


def main():
    print("""
╔══════════════════════════════════════════════════════════╗
║     Week 2 Day 1-2: 大模型微调                            ║
║     阿里云大模型ACP认证备考 (16%)                         ║
╚══════════════════════════════════════════════════════════╝
""")
    exercises = {
        "1": exercise1_selection,
        "2": exercise2_lora,
        "3": exercise3_data_format,
        "4": exercise4_training,
        "5": exercise5_bailian,
    }

    print("选择: 1.技术选型 2.LoRA 3.数据格式 4.训练参数 5.百炼流程 0.全部")
    choice = input("请选择 (0-5): ").strip()

    if choice == "0":
        for f in exercises.values():
            f()
    elif choice in exercises:
        exercises[choice]()

    print("\n✅ Week 2 Day 1-2 完成！")


if __name__ == "__main__":
    main()
