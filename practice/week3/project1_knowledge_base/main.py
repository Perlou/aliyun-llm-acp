"""
Week 3 Project 1: ä¼ä¸šçŸ¥è¯†åº“é—®ç­”ç³»ç»Ÿ
é˜¿é‡Œäº‘å¤§æ¨¡å‹ACPè®¤è¯å¤‡è€ƒ - é˜¶æ®µäºŒå®è·µé¡¹ç›®

æŠ€æœ¯æ ˆ: LlamaIndex + DashScope + RAG
è¦†ç›–è€ƒç‚¹: RAG (24%) + Prompt (24%) + åº”ç”¨å¼€å‘ (16%)

è¿è¡Œå‰è¯·è®¾ç½®:
export DASHSCOPE_API_KEY="your_api_key"

ä¾èµ–å®‰è£…:
pip install llama-index llama-index-llms-dashscope llama-index-embeddings-dashscope
"""

import os
from pathlib import Path

# ============================================================
# é…ç½®
# ============================================================
API_KEY = os.getenv("DASHSCOPE_API_KEY", "")
DATA_DIR = Path(__file__).parent / "data"
INDEX_DIR = Path(__file__).parent / "index"


def check_environment():
    """æ£€æŸ¥ç¯å¢ƒé…ç½®"""
    print("=" * 60)
    print("ç¯å¢ƒæ£€æŸ¥")
    print("=" * 60)

    if not API_KEY:
        print("âŒ DASHSCOPE_API_KEY æœªè®¾ç½®")
        print("   è¯·è¿è¡Œ: export DASHSCOPE_API_KEY='your_key'")
        return False
    else:
        print(f"âœ… API Key å·²é…ç½® ({API_KEY[:8]}...)")

    # åˆ›å»ºæ•°æ®ç›®å½•
    DATA_DIR.mkdir(parents=True, exist_ok=True)
    INDEX_DIR.mkdir(parents=True, exist_ok=True)
    print(f"âœ… æ•°æ®ç›®å½•: {DATA_DIR}")
    print(f"âœ… ç´¢å¼•ç›®å½•: {INDEX_DIR}")

    return True


# ============================================================
# Step 1: æ–‡æ¡£å‡†å¤‡
# ============================================================
def step1_prepare_documents():
    """å‡†å¤‡ç¤ºä¾‹æ–‡æ¡£"""
    print("\n" + "=" * 60)
    print("Step 1: å‡†å¤‡æ–‡æ¡£")
    print("=" * 60)

    # åˆ›å»ºç¤ºä¾‹æ–‡æ¡£ - é˜¿é‡Œäº‘ç™¾ç‚¼å¹³å°ä»‹ç»
    docs = {
        "bailian_overview.txt": """
é˜¿é‡Œäº‘ç™¾ç‚¼å¹³å°æ¦‚è¿°

ç™¾ç‚¼æ˜¯é˜¿é‡Œäº‘æ¨å‡ºçš„ä¸€ç«™å¼å¤§æ¨¡å‹åº”ç”¨å¼€å‘å¹³å°ï¼Œå¸®åŠ©ä¼ä¸šå’Œå¼€å‘è€…å¿«é€Ÿæ„å»ºAIåº”ç”¨ã€‚

ä¸»è¦åŠŸèƒ½åŒ…æ‹¬ï¼š
1. æ¨¡å‹æœåŠ¡ï¼šæä¾›é€šä¹‰åƒé—®ç³»åˆ—æ¨¡å‹ï¼Œæ”¯æŒæ–‡æœ¬ç”Ÿæˆã€å¯¹è¯ã€ä»£ç ç­‰èƒ½åŠ›
2. çŸ¥è¯†åº“ï¼šæ”¯æŒæ–‡æ¡£ä¸Šä¼ ã€è§£æã€å‘é‡åŒ–ï¼Œæ„å»ºä¼ä¸šä¸“å±çŸ¥è¯†åº“
3. åº”ç”¨æ„å»ºï¼šé›¶ä»£ç /ä½ä»£ç æ–¹å¼å¿«é€Ÿæ­å»ºAIåº”ç”¨
4. æ¨¡å‹å¾®è°ƒï¼šæ”¯æŒLoRAç­‰å¾®è°ƒæ–¹å¼ï¼Œå®šåˆ¶ä¸“å±æ¨¡å‹
5. Agentå¼€å‘ï¼šé€šè¿‡Assistant APIæ„å»ºæ™ºèƒ½ä½“åº”ç”¨

ç™¾ç‚¼å¹³å°æ”¯æŒçš„æ¨¡å‹ï¼š
- Qwen-Maxï¼šæœ€å¼ºæ–‡æœ¬ç†è§£å’Œç”Ÿæˆèƒ½åŠ›
- Qwen-Plusï¼šæ€§ä»·æ¯”ç‰ˆæœ¬
- Qwen-Turboï¼šå¿«é€Ÿå“åº”ç‰ˆæœ¬
- Qwen-VLï¼šè§†è§‰ç†è§£æ¨¡å‹
- Qwen-Audioï¼šè¯­éŸ³å¤„ç†æ¨¡å‹
""",
        "rag_introduction.txt": """
RAG (æ£€ç´¢å¢å¼ºç”Ÿæˆ) æŠ€æœ¯ä»‹ç»

RAGæ˜¯ä¸€ç§ç»“åˆæ£€ç´¢å’Œç”Ÿæˆçš„æŠ€æœ¯ï¼Œé€šè¿‡æ£€ç´¢å¤–éƒ¨çŸ¥è¯†æ¥å¢å¼ºå¤§æ¨¡å‹çš„å›ç­”èƒ½åŠ›ã€‚

RAGçš„æ ¸å¿ƒæµç¨‹ï¼š
1. æ–‡æ¡£è§£æ (Document Parsing)ï¼šå°†PDFã€Wordç­‰æ–‡æ¡£è§£æä¸ºæ–‡æœ¬
2. æ–‡æœ¬åˆ‡ç‰‡ (Chunking)ï¼šå°†é•¿æ–‡æœ¬åˆ‡åˆ†ä¸ºé€‚åˆæ£€ç´¢çš„ç‰‡æ®µ
3. å‘é‡åŒ– (Embedding)ï¼šå°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡è¡¨ç¤º
4. ç´¢å¼•å­˜å‚¨ (Indexing)ï¼šå°†å‘é‡å­˜å…¥å‘é‡æ•°æ®åº“
5. æ£€ç´¢ (Retrieval)ï¼šæ ¹æ®ç”¨æˆ·æŸ¥è¯¢æ£€ç´¢ç›¸å…³ç‰‡æ®µ
6. ç”Ÿæˆ (Generation)ï¼šå°†æ£€ç´¢ç»“æœä¸æŸ¥è¯¢ä¸€èµ·è¾“å…¥å¤§æ¨¡å‹ç”Ÿæˆå›ç­”

RAGçš„ä¼˜åŠ¿ï¼š
- çŸ¥è¯†å¯æ›´æ–°ï¼šæ— éœ€é‡æ–°è®­ç»ƒæ¨¡å‹
- å¯æº¯æºï¼šå›ç­”å¯è¿½æº¯åˆ°åŸå§‹æ–‡æ¡£
- æˆæœ¬ä½ï¼šä¸éœ€è¦æ¨¡å‹å¾®è°ƒ
- å‡å°‘å¹»è§‰ï¼šåŸºäºçœŸå®æ–‡æ¡£å›ç­”

RAGè¯„æµ‹æŒ‡æ ‡ (RAGAS)ï¼š
- Faithfulnessï¼šå¿ å®åº¦ï¼Œç­”æ¡ˆæ˜¯å¦åŸºäºæ£€ç´¢å†…å®¹
- Answer Relevancyï¼šç­”æ¡ˆç›¸å…³æ€§
- Context Precisionï¼šä¸Šä¸‹æ–‡ç²¾ç¡®åº¦
- Context Recallï¼šä¸Šä¸‹æ–‡å¬å›ç‡
""",
        "prompt_engineering.txt": """
æç¤ºè¯å·¥ç¨‹æœ€ä½³å®è·µ

æç¤ºè¯å·¥ç¨‹æ˜¯ä¼˜åŒ–å¤§æ¨¡å‹è¾“å‡ºçš„å…³é”®æŠ€æœ¯ã€‚

System Prompt è®¾è®¡è¦ç´ ï¼š
1. è§’è‰²å®šä¹‰ï¼šæ˜ç¡®AIçš„èº«ä»½å’Œä¸“ä¸šé¢†åŸŸ
2. ä»»åŠ¡æè¿°ï¼šæ¸…æ™°è¯´æ˜éœ€è¦å®Œæˆçš„å…·ä½“ç›®æ ‡
3. è¾“å‡ºæ ¼å¼ï¼šæŒ‡å®šå›ç­”çš„æ ¼å¼è¦æ±‚
4. çº¦æŸæ¡ä»¶ï¼šè®¾å®šé™åˆ¶å’Œè¾¹ç•Œ

å¸¸ç”¨åˆ†éš”ç¬¦ï¼š
- ### ç”¨äºåˆ†éš”ä¸åŒéƒ¨åˆ†
- \"\"\" ç”¨äºåŒ…è£¹é•¿æ–‡æœ¬
- <tag> XMLæ ‡ç­¾ç”¨äºç»“æ„åŒ–

æç¤ºè¯å®‰å…¨ï¼š
- ä½¿ç”¨åˆ†éš”ç¬¦éš”ç¦»ç”¨æˆ·è¾“å…¥
- æ£€æµ‹æç¤ºæ³¨å…¥æ”»å‡»
- è¾“å…¥è¾“å‡ºåŒé‡æ ¡éªŒ

ç¤ºä¾‹ - å®¢æœåˆ†ç±»æç¤ºè¯ï¼š
ä½ æ˜¯ä¸€ä¸ªå®¢æœæ„å›¾åˆ†ç±»å™¨ã€‚
å°†ç”¨æˆ·è¾“å…¥åˆ†ç±»ä¸ºï¼šæŸ¥è¯¢è®¢å•/é€€æ¬¾ç”³è¯·/äº§å“å’¨è¯¢/æŠ•è¯‰å»ºè®®/å…¶ä»–
åªè¾“å‡ºç±»åˆ«åç§°ï¼Œä¸è¦è§£é‡Šã€‚
""",
    }

    for filename, content in docs.items():
        filepath = DATA_DIR / filename
        filepath.write_text(content.strip(), encoding="utf-8")
        print(f"âœ… åˆ›å»ºæ–‡æ¡£: {filename}")

    print(f"\nğŸ“ æ–‡æ¡£ç›®å½•: {DATA_DIR}")
    return True


# ============================================================
# Step 2: æ„å»ºç´¢å¼•
# ============================================================
def step2_build_index():
    """æ„å»ºå‘é‡ç´¢å¼•"""
    print("\n" + "=" * 60)
    print("Step 2: æ„å»ºå‘é‡ç´¢å¼•")
    print("=" * 60)

    if not API_KEY:
        print("âš ï¸ éœ€è¦ API Keyï¼Œè·³è¿‡å®é™…æ„å»º")
        print_index_concept()
        return None

    try:
        from llama_index.core import (
            VectorStoreIndex,
            SimpleDirectoryReader,
            Settings,
            StorageContext,
            load_index_from_storage,
        )
        from llama_index.llms.dashscope import DashScope
        from llama_index.embeddings.dashscope import DashScopeEmbedding

        # é…ç½®æ¨¡å‹
        Settings.llm = DashScope(model_name="qwen-max", api_key=API_KEY)
        Settings.embed_model = DashScopeEmbedding(
            model_name="text-embedding-v2", api_key=API_KEY
        )

        print("âœ… æ¨¡å‹é…ç½®å®Œæˆ: qwen-max + text-embedding-v2")

        # æ£€æŸ¥æ˜¯å¦å·²æœ‰ç´¢å¼•
        if (INDEX_DIR / "docstore.json").exists():
            print("ğŸ“¦ å‘ç°å·²æœ‰ç´¢å¼•ï¼Œæ­£åœ¨åŠ è½½...")
            storage_context = StorageContext.from_defaults(persist_dir=str(INDEX_DIR))
            index = load_index_from_storage(storage_context)
            print("âœ… ç´¢å¼•åŠ è½½å®Œæˆ")
        else:
            # è¯»å–æ–‡æ¡£
            print("ğŸ“– æ­£åœ¨è¯»å–æ–‡æ¡£...")
            documents = SimpleDirectoryReader(str(DATA_DIR)).load_data()
            print(f"âœ… è¯»å–äº† {len(documents)} ä¸ªæ–‡æ¡£")

            # æ„å»ºç´¢å¼•
            print("ğŸ”¨ æ­£åœ¨æ„å»ºå‘é‡ç´¢å¼•...")
            index = VectorStoreIndex.from_documents(documents)

            # æŒä¹…åŒ–
            index.storage_context.persist(persist_dir=str(INDEX_DIR))
            print(f"âœ… ç´¢å¼•å·²ä¿å­˜åˆ°: {INDEX_DIR}")

        return index

    except ImportError as e:
        print(f"âŒ ç¼ºå°‘ä¾èµ–: {e}")
        print(
            "   è¯·è¿è¡Œ: pip install llama-index llama-index-llms-dashscope llama-index-embeddings-dashscope"
        )
        return None


def print_index_concept():
    """æ‰“å°ç´¢å¼•æ¦‚å¿µè¯´æ˜"""
    print("""
ğŸ“Š å‘é‡ç´¢å¼•æ„å»ºæµç¨‹:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. è¯»å–æ–‡æ¡£                                                  â”‚
â”‚    SimpleDirectoryReader(data_dir).load_data()              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2. æ–‡æœ¬åˆ‡ç‰‡ (è‡ªåŠ¨)                                           â”‚
â”‚    é»˜è®¤ chunk_size=1024, chunk_overlap=20                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 3. å‘é‡åŒ–                                                    â”‚
â”‚    ä½¿ç”¨ DashScopeEmbedding (text-embedding-v2)             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 4. æ„å»ºç´¢å¼•                                                  â”‚
â”‚    VectorStoreIndex.from_documents(documents)               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 5. æŒä¹…åŒ–                                                    â”‚
â”‚    index.storage_context.persist(persist_dir)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
""")


# ============================================================
# Step 3: é—®ç­”æŸ¥è¯¢
# ============================================================
def step3_query(index=None):
    """é—®ç­”æŸ¥è¯¢"""
    print("\n" + "=" * 60)
    print("Step 3: é—®ç­”æŸ¥è¯¢")
    print("=" * 60)

    if index is None:
        print("âš ï¸ ç´¢å¼•æœªæ„å»ºï¼Œå±•ç¤ºæŸ¥è¯¢æ¦‚å¿µ")
        print_query_concept()
        return

    # åˆ›å»ºæŸ¥è¯¢å¼•æ“
    query_engine = index.as_query_engine(
        similarity_top_k=3,  # æ£€ç´¢ top 3 ç›¸å…³ç‰‡æ®µ
    )

    # æµ‹è¯•æŸ¥è¯¢
    test_questions = [
        "ç™¾ç‚¼å¹³å°æœ‰å“ªäº›ä¸»è¦åŠŸèƒ½ï¼Ÿ",
        "RAGçš„æ ¸å¿ƒæµç¨‹æ˜¯ä»€ä¹ˆï¼Ÿ",
        "å¦‚ä½•è®¾è®¡å¥½çš„System Promptï¼Ÿ",
    ]

    for q in test_questions:
        print(f"\nâ“ é—®é¢˜: {q}")
        print("-" * 50)
        response = query_engine.query(q)
        print(f"ğŸ’¡ å›ç­”: {response}")


def print_query_concept():
    """æ‰“å°æŸ¥è¯¢æ¦‚å¿µè¯´æ˜"""
    print("""
ğŸ“Š RAG æŸ¥è¯¢æµç¨‹:

```python
# åˆ›å»ºæŸ¥è¯¢å¼•æ“
query_engine = index.as_query_engine(
    similarity_top_k=3,       # æ£€ç´¢æ•°é‡
    response_mode="compact",  # å“åº”æ¨¡å¼
)

# æ‰§è¡ŒæŸ¥è¯¢
response = query_engine.query("é—®é¢˜å†…å®¹")

# è·å–æºæ–‡æ¡£
for node in response.source_nodes:
    print(node.text)       # åŸæ–‡
    print(node.score)      # ç›¸ä¼¼åº¦åˆ†æ•°
```

ğŸ“Š å…³é”®å‚æ•°:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ å‚æ•°                 â”‚ è¯´æ˜                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ similarity_top_k    â”‚ æ£€ç´¢è¿”å›çš„æ–‡æ¡£æ•°é‡                   â”‚
â”‚ response_mode       â”‚ compact/refine/tree_summarize      â”‚
â”‚ streaming           â”‚ æ˜¯å¦æµå¼è¾“å‡º                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
""")


# ============================================================
# Step 4: é«˜çº§ä¼˜åŒ–
# ============================================================
def step4_optimization():
    """RAG ä¼˜åŒ–æŠ€æœ¯"""
    print("\n" + "=" * 60)
    print("Step 4: RAG ä¼˜åŒ–æŠ€æœ¯")
    print("=" * 60)

    print("""
ğŸ“Š åˆ‡ç‰‡ä¼˜åŒ–

```python
from llama_index.core.node_parser import SentenceSplitter

# è‡ªå®šä¹‰åˆ‡ç‰‡
splitter = SentenceSplitter(
    chunk_size=512,    # æ¯ä¸ªç‰‡æ®µå¤§å°
    chunk_overlap=50,  # é‡å éƒ¨åˆ†
)
nodes = splitter.get_nodes_from_documents(documents)
```

ğŸ“Š å¥å­çª—å£æ£€ç´¢ (Sentence Window)

åŸç†: æ£€ç´¢æ—¶åŒ¹é…å¥å­ï¼Œè¿”å›æ—¶åŒ…å«ä¸Šä¸‹æ–‡çª—å£

```python
from llama_index.core.node_parser import SentenceWindowNodeParser

parser = SentenceWindowNodeParser.from_defaults(
    window_size=3,  # ä¸Šä¸‹æ–‡çª—å£å¤§å°
)
```

ğŸ“Š æ··åˆæ£€ç´¢ (Hybrid Search)

åŸç†: ç»“åˆç¨€ç–æ£€ç´¢ (BM25) å’Œç¨ å¯†æ£€ç´¢ (å‘é‡)

```python
# æ··åˆæ£€ç´¢å¾—åˆ† = Î± Ã— sparse + (1-Î±) Ã— dense
from llama_index.core.retrievers import BM25Retriever

bm25_retriever = BM25Retriever.from_defaults(nodes=nodes)
```

ğŸ“Š é‡æ’åº (Re-ranking)

åŸç†: å¯¹æ£€ç´¢ç»“æœè¿›è¡Œç²¾æ’

```python
from llama_index.core.postprocessor import SentenceTransformerRerank

rerank = SentenceTransformerRerank(
    model="cross-encoder/ms-marco-MiniLM-L-6-v2",
    top_n=3,
)
query_engine = index.as_query_engine(
    node_postprocessors=[rerank]
)
```
""")


# ============================================================
# ä¸»ç¨‹åº
# ============================================================
def main():
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘     Week 3 Project 1: ä¼ä¸šçŸ¥è¯†åº“é—®ç­”ç³»ç»Ÿ                  â•‘
â•‘     é˜¿é‡Œäº‘å¤§æ¨¡å‹ACPè®¤è¯å¤‡è€ƒ - é˜¶æ®µäºŒå®è·µ                  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")

    print("é€‰æ‹©è¿è¡Œæ­¥éª¤:")
    print("  1. ç¯å¢ƒæ£€æŸ¥")
    print("  2. å‡†å¤‡æ–‡æ¡£")
    print("  3. æ„å»ºç´¢å¼•")
    print("  4. é—®ç­”æŸ¥è¯¢")
    print("  5. ä¼˜åŒ–æŠ€æœ¯")
    print("  0. å®Œæ•´æµç¨‹")

    choice = input("\nè¯·é€‰æ‹© (0-5): ").strip()

    if choice == "1":
        check_environment()
    elif choice == "2":
        step1_prepare_documents()
    elif choice == "3":
        if check_environment():
            step2_build_index()
    elif choice == "4":
        if check_environment():
            index = step2_build_index()
            step3_query(index)
    elif choice == "5":
        step4_optimization()
    elif choice == "0":
        if check_environment():
            step1_prepare_documents()
            index = step2_build_index()
            step3_query(index)
            step4_optimization()
    else:
        print("æ— æ•ˆé€‰æ‹©")

    print("\n" + "=" * 60)
    print("âœ… Project 1 å®Œæˆï¼")
    print("=" * 60)


if __name__ == "__main__":
    main()
