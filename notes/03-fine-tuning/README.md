# 🔧 大模型微调 (Fine-tuning)

> 📊 **考试占比**: 16% (~16 题)
>
> 🎯 **重要程度**: ⭐⭐⭐⭐

## 📚 知识大纲

### 1. 微调基础概念

#### 1.1 什么是模型微调

- 在预训练模型基础上，使用特定领域数据继续训练
- 调整模型参数以适应特定任务或领域

#### 1.2 何时使用微调

| 场景         | 推荐方案 | 原因               |
| ------------ | -------- | ------------------ |
| 知识库问答   | RAG      | 知识可更新，可溯源 |
| 特定写作风格 | 微调     | 需要改变生成模式   |
| 专业术语理解 | 微调     | 需要学习新概念     |
| 实时信息查询 | RAG      | 数据频繁更新       |
| 格式化输出   | 微调     | 稳定的输出格式     |

#### 1.3 微调 vs Prompt Engineering vs RAG

```
┌────────────────────────────────────────────────────────────┐
│         选择决策树                                          │
├────────────────────────────────────────────────────────────┤
│                                                             │
│  问题: 模型表现不佳?                                         │
│         │                                                   │
│         ↓                                                   │
│  ┌─────────────────────────────────────┐                    │
│  │ 问题是缺少特定知识?                   │                    │
│  │ Yes → 使用 RAG (知识库)              │                    │
│  │ No  → 继续判断                       │                    │
│  └─────────────────────────────────────┘                    │
│         │                                                   │
│         ↓ No                                                │
│  ┌─────────────────────────────────────┐                    │
│  │ 问题可通过更好的提示词解决?            │                    │
│  │ Yes → 优化 Prompt                    │                    │
│  │ No  → 继续判断                       │                    │
│  └─────────────────────────────────────┘                    │
│         │                                                   │
│         ↓ No                                                │
│  ┌─────────────────────────────────────┐                    │
│  │ 需要改变模型行为/风格?                │                    │
│  │ Yes → 模型微调                       │                    │
│  └─────────────────────────────────────┘                    │
│                                                             │
└────────────────────────────────────────────────────────────┘
```

### 2. 常用微调算法 ⭐

#### 2.1 全参数微调 (Full Fine-tuning)

- 更新模型所有参数
- 效果最好，但成本最高
- 需要大量 GPU 资源

#### 2.2 参数高效微调 (PEFT)

| 方法              | 原理         | 优点         | 参数量 |
| ----------------- | ------------ | ------------ | ------ |
| **LoRA**          | 低秩矩阵分解 | 高效、可插拔 | ~0.1%  |
| **QLoRA**         | LoRA + 量化  | 更省资源     | ~0.1%  |
| **Adapter**       | 插入适配层   | 模块化       | ~3%    |
| **Prefix Tuning** | 前缀向量调优 | 简单         | <1%    |

#### 2.3 LoRA 原理详解

```
原始权重: W (d × d)
分解为: W + ΔW = W + BA

其中:
- B: (d × r) 矩阵
- A: (r × d) 矩阵
- r: 秩，远小于 d (如 r=8)

参数量: 2 × d × r << d × d
```

```python
# LoRA 核心参数
lora_config = {
    "r": 8,           # 秩，越大表达能力越强
    "lora_alpha": 32, # 缩放因子
    "lora_dropout": 0.1,
    "target_modules": ["q_proj", "v_proj"]  # 目标层
}
```

### 3. 微调数据准备 ⭐

#### 3.1 数据格式标准

```json
// 指令微调格式 (Instruction Tuning)
{
  "instruction": "将以下文本翻译成英文",
  "input": "今天天气很好",
  "output": "The weather is nice today"
}

// 对话格式
{
  "conversations": [
    {"role": "user", "content": "你好"},
    {"role": "assistant", "content": "你好！有什么可以帮助你的？"}
  ]
}
```

#### 3.2 数据质量要求

```
✅ 高质量数据特征:
├── 准确性: 输出正确无误
├── 一致性: 格式统一规范
├── 多样性: 覆盖不同场景
├── 代表性: 反映真实分布
└── 适量性: 通常 1000-10000 条

❌ 避免的问题:
├── 重复数据
├── 标注错误
├── 格式混乱
└── 数据泄露
```

#### 3.3 数据量建议

| 任务类型 | 建议数据量 |
| -------- | ---------- |
| 简单分类 | 100-500    |
| 对话风格 | 500-2000   |
| 专业领域 | 2000-10000 |
| 复杂推理 | 10000+     |

### 4. 微调参数详解

#### 4.1 核心训练参数

| 参数            | 说明     | 常见值      |
| --------------- | -------- | ----------- |
| `learning_rate` | 学习率   | 1e-5 ~ 5e-5 |
| `epochs`        | 训练轮次 | 3-5         |
| `batch_size`    | 批量大小 | 4-32        |
| `warmup_ratio`  | 预热比例 | 0.1         |
| `weight_decay`  | 权重衰减 | 0.01        |

#### 4.2 参数调优建议

```
学习率:
├── 过大 → 训练不稳定，loss 震荡
└── 过小 → 收敛慢，可能欠拟合

Epochs:
├── 过多 → 过拟合
└── 过少 → 欠拟合

Batch Size:
├── 越大 → 训练越稳定，但显存需求高
└── 越小 → 梯度噪声大，但可能帮助泛化
```

### 5. 模型评测

#### 5.1 评测指标

| 指标           | 适用场景  | 说明             |
| -------------- | --------- | ---------------- |
| **Loss**       | 通用      | 越低越好         |
| **Accuracy**   | 分类任务  | 准确率           |
| **BLEU**       | 翻译/生成 | n-gram 匹配度    |
| **ROUGE**      | 摘要生成  | 召回导向         |
| **Perplexity** | 语言模型  | 困惑度，越低越好 |

#### 5.2 评测方法

```python
# 常见评测流程
1. 划分测试集 (通常 10-20%)
2. 在测试集上推理
3. 计算评测指标
4. 人工抽样评估
```

### 6. 百炼平台微调流程

```
百炼微调流程:
1. 准备数据集 → 上传 JSONL 文件
2. 创建微调任务 → 选择基础模型
3. 配置参数 → 设置训练参数
4. 启动训练 → 等待完成
5. 模型评测 → 测试效果
6. 部署上线 → 发布 API
```

---

## ✅ 知识点自测

1. [ ] 何时选择微调而非 RAG?
2. [ ] LoRA 的核心原理是什么?
3. [ ] 微调数据的标准格式?
4. [ ] learning_rate 过大会有什么问题?
5. [ ] 如何评估微调效果?

---

## 📝 考点速记卡

```
🔹 微调 = 改变模型参数，适应特定任务
🔹 RAG = 知识补充，微调 = 行为改变
🔹 LoRA = 低秩分解，参数量 ~0.1%
🔹 QLoRA = LoRA + 量化，更省资源
🔹 数据格式 = instruction + input + output
🔹 lr↑ = 不稳定，epochs↑ = 过拟合
```
